{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000000', '00000001', '00000010', '00000011', '00000100', '00000101', '00000110', '00000111', '00001000', '00001001', '00001010', '00001011', '00001100', '00001101', '00001110', '00001111', '00010000', '00010001', '00010010', '00010011', '00010100', '00010101', '00010110', '00010111', '00011000', '00011001', '00011010', '00011011', '00011100', '00011101', '00011110', '00011111', '00100000', '00100001', '00100010', '00100011', '00100100', '00100101', '00100110', '00100111', '00101000', '00101001', '00101010', '00101011', '00101100', '00101101', '00101110', '00101111', '00110000', '00110001', '00110010', '00110011', '00110100', '00110101', '00110110', '00110111', '00111000', '00111001', '00111010', '00111011', '00111100', '00111101', '00111110', '00111111', '01000000', '01000001', '01000010', '01000011', '01000100', '01000101', '01000110', '01000111', '01001000', '01001001', '01001010', '01001011', '01001100', '01001101', '01001110', '01001111', '01010000', '01010001', '01010010', '01010011', '01010100', '01010101', '01010110', '01010111', '01011000', '01011001', '01011010', '01011011', '01011100', '01011101', '01011110', '01011111', '01100000', '01100001', '01100010', '01100011', '01100100', '01100101', '01100110', '01100111', '01101000', '01101001', '01101010', '01101011', '01101100', '01101101', '01101110', '01101111', '01110000', '01110001', '01110010', '01110011', '01110100', '01110101', '01110110', '01110111', '01111000', '01111001', '01111010', '01111011', '01111100', '01111101', '01111110', '01111111', '10000000', '10000001', '10000010', '10000011', '10000100', '10000101', '10000110', '10000111', '10001000', '10001001', '10001010', '10001011', '10001100', '10001101', '10001110', '10001111', '10010000', '10010001', '10010010', '10010011', '10010100', '10010101', '10010110', '10010111', '10011000', '10011001', '10011010', '10011011', '10011100', '10011101', '10011110', '10011111', '10100000', '10100001', '10100010', '10100011', '10100100', '10100101', '10100110', '10100111', '10101000', '10101001', '10101010', '10101011', '10101100', '10101101', '10101110', '10101111', '10110000', '10110001', '10110010', '10110011', '10110100', '10110101', '10110110', '10110111', '10111000', '10111001', '10111010', '10111011', '10111100', '10111101', '10111110', '10111111', '11000000', '11000001', '11000010', '11000011', '11000100', '11000101', '11000110', '11000111', '11001000', '11001001', '11001010', '11001011', '11001100', '11001101', '11001110', '11001111', '11010000', '11010001', '11010010', '11010011', '11010100', '11010101', '11010110', '11010111', '11011000', '11011001', '11011010', '11011011', '11011100', '11011101', '11011110', '11011111', '11100000', '11100001', '11100010', '11100011', '11100100', '11100101', '11100110', '11100111', '11101000', '11101001', '11101010', '11101011', '11101100', '11101101', '11101110', '11101111', '11110000', '11110001', '11110010', '11110011', '11110100', '11110101', '11110110', '11110111', '11111000', '11111001', '11111010', '11111011', '11111100', '11111101', '11111110', '11111111']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import Aer, execute\n",
    "from scipy.optimize import minimize\n",
    "#way to visualize the graphs\n",
    "def DrawGraph(Graph):\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "    pos=nx.spring_layout(Graph) \n",
    "    nx.draw_networkx(Graph,pos)\n",
    "    labels = nx.get_edge_attributes(Graph,'weight')\n",
    "    nx.draw_networkx_edge_labels(Graph,pos,edge_labels=labels)\n",
    "    plt.show()\n",
    "    return \n",
    "#way to convert the graphs to a easy formatable manner\n",
    "def matrix_to_edges(matrix):\n",
    "    edges = []\n",
    "    num_rows, num_cols = matrix.shape\n",
    "\n",
    "    for row in range(num_rows):\n",
    "        for col in range(row,num_cols):\n",
    "            if matrix[row, col] != 0 and row!=col:\n",
    "                edges.append((row, col))\n",
    "\n",
    "    return edges\n",
    "\n",
    "from qiskit import QuantumCircuit, Aer\n",
    "from qiskit.circuit import Parameter\n",
    "def generate_binary_strings():\n",
    "    binary_strings = []\n",
    "    for i in range(256):\n",
    "        binary_string = format(i, '08b')\n",
    "        binary_strings.append(binary_string)\n",
    "    return binary_strings\n",
    "binary_strings = generate_binary_strings()\n",
    "print(binary_strings)\n",
    "def order_dictionary(dictionary):\n",
    "    ordered_dict = {}\n",
    "    sorted_keys = binary_strings  # Sort the keys in ascending order\n",
    "    for key in sorted_keys:\n",
    "        ordered_dict[key] = dictionary.get(key, 0)  # Add key-value pairs to the ordered dictionary\n",
    "    dict_jdd = {}\n",
    "    for i in range(128):\n",
    "        dict_jdd[binary_strings[i]]=ordered_dict[binary_strings[i]] + ordered_dict[binary_strings[255-i]]\n",
    "    return dict_jdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12346\n"
     ]
    }
   ],
   "source": [
    "#here I am going to import the data that we set for the NN network\n",
    "# Specify the file path of the pickle file\n",
    "file_path = r'C:\\Users\\evilb\\OneDrive - University of Tennessee\\Research_Work\\QAOA\\QAOACountsJuly7_8.pkl'\n",
    "\n",
    "# Open the pickle file in binary mode and load the data using pickle.load()\n",
    "with open(file_path, 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "\n",
    "# Now you can use the loaded dictionary\n",
    "print(len(data_dict['graphs']))\n",
    "from torchvision import datasets, transforms\n",
    "import itertools\n",
    "array = torch.arange(12346)\n",
    "# Get the size of the array\n",
    "n = array.size(0)\n",
    "# Generate a random permutation\n",
    "torch.manual_seed(42)\n",
    "perm = torch.randperm(n)\n",
    "# Use the permutation to randomly organize the array\n",
    "random_array = array[perm]\n",
    "\n",
    "traina = []\n",
    "vala=[]\n",
    "valnums=[]\n",
    "trainnums = []\n",
    "valclock=0\n",
    "for i in range(0,9877):\n",
    "    #pay close attendtion to how I fill traina and vala. I call for traina[0] for the counts and so on.\n",
    "    traina.append([list(data_dict['counts'][random_array[i]].values())])\n",
    "    traina[i].append(list(data_dict['obj_sol'][random_array[i]]))\n",
    "    traina[i].append(list(data_dict['binary_sol'][random_array[i]]))\n",
    "    traina[i].append(list(data_dict['graphs'][random_array[i]]))\n",
    "    trainnums.append(i)\n",
    "    #try to append it to the array : trainset[i].append\n",
    "for i in range(9877,12346):\n",
    "    vala.append([list(data_dict['counts'][random_array[i]].values())])\n",
    "    vala[valclock].append(list(data_dict['obj_sol'][random_array[i]]))\n",
    "    vala[valclock].append(list(data_dict['binary_sol'][random_array[i]]))\n",
    "    vala[valclock].append(list(data_dict['graphs'][random_array[i]]))\n",
    "    valnums.append(valclock)\n",
    "    valclock+=1\n",
    "trainset = torch.tensor(trainnums)\n",
    "valset = torch.tensor(valnums)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I make simple fully connected models to test the legitamacy of training a NN to predict the maximum cut and optimal solution from just the distribution, the graph, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleDistToOptSol(\n",
      "  (hidden1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (hidden2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (hidden3): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (hidden4): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (output): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "SimpleGraphToOptSol(\n",
      "  (hidden1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (hidden2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (hidden3): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (hidden4): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (output): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "SimpleGraphDistToOptSol(\n",
      "  (hidden1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (hidden2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (hidden3): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (hidden4): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (output): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (hidden5): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (hidden6): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (hidden7): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (hidden8): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (hidden9): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (hidden10): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (hidden11): Linear(in_features=16, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleDistToOptSol(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleDistToOptSol, self).__init__()\n",
    "        self.hidden1 = nn.Linear(128, 64)\n",
    "        self.hidden2 = nn.Linear(64, 32)\n",
    "        self.hidden3 = nn.Linear(32, 16)\n",
    "        self.hidden4 = nn.Linear(16, 16)\n",
    "        self.output = nn.Linear(16, 8)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        x = torch.relu(self.hidden4(x))\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "# Create an instance of the neural network\n",
    "net1 = SimpleDistToOptSol()\n",
    "# Print the architecture of the network\n",
    "print(net1)\n",
    "\n",
    "class SimpleGraphToOptSol(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleGraphToOptSol, self).__init__()\n",
    "        self.hidden1 = nn.Linear(64, 64)\n",
    "        self.hidden2 = nn.Linear(64, 32)\n",
    "        self.hidden3 = nn.Linear(32, 16)\n",
    "        self.hidden4 = nn.Linear(16, 16)\n",
    "        self.output = nn.Linear(16, 8)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.hidden1.weight.dtype)\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        x = torch.relu(self.hidden4(x))\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "# Create an instance of the neural network\n",
    "net2 = SimpleGraphToOptSol()\n",
    "# Print the architecture of the network\n",
    "print(net2)\n",
    "\n",
    "#this next model is the last two combined.\n",
    "class SimpleGraphDistToOptSol(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleGraphDistToOptSol, self).__init__()\n",
    "        self.hidden1 = nn.Linear(64, 64)\n",
    "        self.hidden2 = nn.Linear(64, 32)\n",
    "        self.hidden3 = nn.Linear(32, 16)\n",
    "        self.hidden4 = nn.Linear(16, 16)\n",
    "        self.output = nn.Linear(16, 16)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.hidden5 = nn.Linear(128, 64)\n",
    "        self.hidden6 = nn.Linear(64, 32)\n",
    "        self.hidden7 = nn.Linear(32, 16)\n",
    "        self.hidden8 = nn.Linear(16, 16)\n",
    "        self.output = nn.Linear(16, 16)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.hidden9 = nn.Linear(32,32)\n",
    "        self.hidden10 = nn.Linear(32,16)\n",
    "        self.hidden11 = nn.Linear(16,8)\n",
    "\n",
    "    def forward(self, x, x1):\n",
    "        x = x.to(self.hidden1.weight.dtype)\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.relu(self.hidden3(x))\n",
    "        x = torch.relu(self.hidden4(x))\n",
    "        x = self.output(x)\n",
    "        x1 = torch.relu(self.hidden5(x1))\n",
    "        x1 = torch.relu(self.hidden6(x1))\n",
    "        x1 = torch.relu(self.hidden7(x1))\n",
    "        x1 = torch.relu(self.hidden8(x1))\n",
    "        x1 = self.output(x1)\n",
    "        x = torch.cat((x1, x), dim=1)\n",
    "        x = torch.relu(self.hidden9(x))\n",
    "        x = torch.relu(self.hidden10(x))\n",
    "        x = torch.relu(self.hidden11(x))\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "# Create an instance of the neural network\n",
    "net3 = SimpleGraphDistToOptSol()\n",
    "# Print the architecture of the network\n",
    "print(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph_opt(model,optimizer,loss_fn,train_loader, val_loader,epochs,dataset,number1,number2):\n",
    "    #time0 = time()\n",
    "    device = \"cpu\"\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(device)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        loss_fn.to(device)\n",
    "        for ticks in train_loader:\n",
    "            histo=[]\n",
    "            gatrix=[]\n",
    "            for i in range(0,len(ticks)):\n",
    "                histo.append(traina[ticks[i]][number1])\n",
    "                gatrix.append(traina[ticks[i]][number2])\n",
    "            gatrix = [[int(bit) for bit in binary_string] for binary_string in gatrix]\n",
    "            inputs = torch.squeeze(torch.tensor(histo), dim=1).to(device)\n",
    "            target = torch.squeeze(torch.tensor(gatrix), dim=1).type(torch.float).to(device)\n",
    "            #print(inputs.shape)\n",
    "\n",
    "        \n",
    "            # Training pass\n",
    "            optimizer.zero_grad()\n",
    "            #inputs = inputs.requires_grad_()  # Enable gradient tracking\n",
    "            output = model(inputs)\n",
    "            #print(output.squeeze().shape, target.shape)\n",
    "            loss1 = loss_fn(output.squeeze(), target)\n",
    "            loss=loss1\n",
    "            #loss.requires_grad=True\n",
    "            #a=list(model.parameters())[0].clone()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #b=list(model.parameters())[0].clone()\n",
    "            #print(torch.equal(a.data,b.data))\n",
    "            running_loss += loss.item()\n",
    "        #training_loss /= len(train_loader)\n",
    "        else:\n",
    "            print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(trainloader)))\n",
    "        test_graph_sol(model,optimizer,loss_fn, val_loader,dataset,number1,number2)\n",
    "        test_graph_sol(model,optimizer,loss_fn, train_loader,traina,number1,number2)\n",
    "\n",
    "def test_graph_sol(model,optimizer,loss_fn, val_loader,dataset,number1,number2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    num_correct =0\n",
    "    num=0\n",
    "    num_correct_graphs=0\n",
    "    model.to(device)\n",
    "    for valticks in val_loader:\n",
    "        valhisto=[]\n",
    "        valgatrix=[]\n",
    "        for i in range(0,len(valticks)):\n",
    "            valhisto.append(dataset[valticks[i]][number1])\n",
    "            valgatrix.append(dataset[valticks[i]][number2])\n",
    "        valgatrix = [[int(bit) for bit in binary_string] for binary_string in valgatrix]\n",
    "        inputs = (torch.squeeze(torch.tensor(valhisto), dim=1)).to(device)\n",
    "        targets = (torch.squeeze(torch.tensor(valgatrix), dim=0).type(torch.float)).to(device)\n",
    "        output =(model(inputs) > 0.5).float().to(device).squeeze()\n",
    "        #print(output.shape, targets.shape)\n",
    "        #print(output)\n",
    "\n",
    "        correct = torch.eq(output,targets)\n",
    "        num +=correct.shape[0]\n",
    "        #print(output,\"-\",targets)\n",
    "        #print(correct)\n",
    "        correct = torch.eq(output,targets)\n",
    "        num_correct +=torch.sum(correct).item()\n",
    "        correct_graphs = torch.all(correct, dim=1, keepdim=True).view(-1)\n",
    "        num_correct_graphs += torch.sum(correct_graphs).item()\n",
    "        #print(num_correct_graphs)\n",
    "    print('accuracy: = {:.2f}, number of graphs: = {:.2f}'.format((num_correct_graphs) / (num),num))\n",
    "        #print(len(output))\n",
    "        #print(len(targets))\n",
    "\n",
    "\n",
    "#----------------------------------\n",
    "#-----------------------------------\n",
    "def train_graph_opt2(model,optimizer,loss_fn,train_loader, val_loader,epochs,dataset,number2):\n",
    "    #time0 = time()\n",
    "    device = \"cpu\"\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(device)\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        loss_fn.to(device)\n",
    "        for ticks in train_loader:\n",
    "            histo1=[]\n",
    "            histo2=[]\n",
    "            gatrix=[]\n",
    "            for i in range(0,len(ticks)):\n",
    "                histo1.append(traina[ticks[i]][3])\n",
    "                histo2.append(traina[ticks[i]][0])\n",
    "                gatrix.append(traina[ticks[i]][number2])\n",
    "            gatrix = [[int(bit) for bit in binary_string] for binary_string in gatrix]\n",
    "            inputs1 = torch.squeeze(torch.tensor(histo1), dim=1).to(device)\n",
    "            inputs2 = torch.squeeze(torch.tensor(histo2), dim=1).to(device)\n",
    "\n",
    "            target = torch.squeeze(torch.tensor(gatrix), dim=1).type(torch.float).to(device)\n",
    "            #print(inputs.shape)\n",
    "\n",
    "        \n",
    "            # Training pass\n",
    "            optimizer.zero_grad()\n",
    "            #inputs = inputs.requires_grad_()  # Enable gradient tracking\n",
    "            output = model(inputs1,inputs2)\n",
    "            #print(output.squeeze().shape, target.shape)\n",
    "            loss1 = loss_fn(output.squeeze(), target)\n",
    "            loss=loss1\n",
    "            #loss.requires_grad=True\n",
    "            #a=list(model.parameters())[0].clone()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #b=list(model.parameters())[0].clone()\n",
    "            #print(torch.equal(a.data,b.data))\n",
    "            running_loss += loss.item()\n",
    "        #training_loss /= len(train_loader)\n",
    "        else:\n",
    "            print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(trainloader)))\n",
    "        test_graph_sol2(model,optimizer,loss_fn, val_loader,dataset,number2)\n",
    "        test_graph_sol2(model,optimizer,loss_fn, train_loader,traina,number2)\n",
    "\n",
    "def test_graph_sol2(model,optimizer,loss_fn, val_loader,dataset,number2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    num_correct =0\n",
    "    num=0\n",
    "    num_correct_graphs=0\n",
    "    model.to(device)\n",
    "    for valticks in val_loader:\n",
    "        valhisto1=[]\n",
    "        valhisto2=[]\n",
    "        valgatrix=[]\n",
    "        for i in range(0,len(valticks)):\n",
    "            valhisto1.append(dataset[valticks[i]][3])\n",
    "            valhisto2.append(dataset[valticks[i]][0])\n",
    "            valgatrix.append(dataset[valticks[i]][number2])\n",
    "        valgatrix = [[int(bit) for bit in binary_string] for binary_string in valgatrix]\n",
    "        inputs1 = (torch.squeeze(torch.tensor(valhisto1), dim=1)).to(device)\n",
    "        inputs2 = (torch.squeeze(torch.tensor(valhisto2), dim=1)).to(device)\n",
    "        targets = (torch.squeeze(torch.tensor(valgatrix), dim=0).type(torch.float)).to(device)\n",
    "        output =(model(inputs1,inputs2) > 0.5).float().to(device).squeeze()\n",
    "        #print(output.shape, targets.shape)\n",
    "        #print(output)\n",
    "\n",
    "        correct = torch.eq(output,targets)\n",
    "        num +=correct.shape[0]\n",
    "        #print(output,\"-\",targets)\n",
    "        #print(output.shape,targets.shape)\n",
    "        #print(correct)\n",
    "        correct = torch.eq(output,targets)\n",
    "        num_correct +=torch.sum(correct).item()\n",
    "        correct_graphs = torch.all(correct, dim=1, keepdim=True).view(-1)\n",
    "        num_correct_graphs += torch.sum(correct_graphs).item()\n",
    "        #print(num_correct_graphs)\n",
    "    print('accuracy: = {:.2f}, number of graphs: = {:.2f}'.format((num_correct_graphs) / (num),num))\n",
    "        #print(len(output))\n",
    "        #print(len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0 - Training loss: 0.7140062436079367\n",
      "accuracy: = 0.08, number of graphs: = 2469.00\n",
      "accuracy: = 0.08, number of graphs: = 9877.00\n",
      "Epoch 1 - Training loss: 0.6711128002557999\n",
      "accuracy: = 0.08, number of graphs: = 2469.00\n",
      "accuracy: = 0.08, number of graphs: = 9877.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#train(hcnet,optim.Adam(hcnet.parameters(), lr=.01), torch.nn.CrossEntropyLoss(),trainloader,valloader, 1000,vala)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_graph_opt(net2,optim\u001b[39m.\u001b[39;49mAdam(net2\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49m\u001b[39m.1\u001b[39;49m), nn\u001b[39m.\u001b[39;49mBCELoss(),trainloader,valloader, \u001b[39m1000\u001b[39;49m,vala,\u001b[39m3\u001b[39;49m,\u001b[39m2\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[123], line 12\u001b[0m, in \u001b[0;36mtrain_graph_opt\u001b[1;34m(model, optimizer, loss_fn, train_loader, val_loader, epochs, dataset, number1, number2)\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m loss_fn\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m ticks \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     13\u001b[0m     histo\u001b[39m=\u001b[39m[]\n\u001b[0;32m     14\u001b[0m     gatrix\u001b[39m=\u001b[39m[]\n",
      "File \u001b[1;32mc:\\Users\\evilb\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:629\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 629\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_name):\n\u001b[0;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m             \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\evilb\\anaconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[0;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\evilb\\anaconda3\\lib\\site-packages\\torch\\_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train(hcnet,optim.Adam(hcnet.parameters(), lr=.01), torch.nn.CrossEntropyLoss(),trainloader,valloader, 1000,vala)\n",
    "train_graph_opt(net2,optim.Adam(net2.parameters(), lr=.1), nn.BCELoss(),trainloader,valloader, 1000,vala,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0 - Training loss: 0.4122377557632251\n",
      "accuracy: = 0.21, number of graphs: = 2469.00\n",
      "accuracy: = 0.21, number of graphs: = 9877.00\n",
      "Epoch 1 - Training loss: 0.2875559123662802\n",
      "accuracy: = 0.21, number of graphs: = 2469.00\n",
      "accuracy: = 0.21, number of graphs: = 9877.00\n",
      "Epoch 2 - Training loss: 0.2871805926163991\n",
      "accuracy: = 0.21, number of graphs: = 2469.00\n",
      "accuracy: = 0.21, number of graphs: = 9877.00\n",
      "Epoch 3 - Training loss: 0.28612974973825306\n",
      "accuracy: = 0.18, number of graphs: = 2469.00\n",
      "accuracy: = 0.19, number of graphs: = 9877.00\n",
      "Epoch 4 - Training loss: 0.2861817631966028\n",
      "accuracy: = 0.07, number of graphs: = 2469.00\n",
      "accuracy: = 0.06, number of graphs: = 9877.00\n",
      "Epoch 5 - Training loss: 0.2854796533401196\n",
      "accuracy: = 0.18, number of graphs: = 2469.00\n",
      "accuracy: = 0.18, number of graphs: = 9877.00\n",
      "Epoch 6 - Training loss: 0.2844198506612044\n",
      "accuracy: = 0.12, number of graphs: = 2469.00\n",
      "accuracy: = 0.12, number of graphs: = 9877.00\n",
      "Epoch 7 - Training loss: 0.28385722866425145\n",
      "accuracy: = 0.21, number of graphs: = 2469.00\n",
      "accuracy: = 0.22, number of graphs: = 9877.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_graph_opt(net1,optim\u001b[39m.\u001b[39;49mAdam(net1\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49m\u001b[39m.01\u001b[39;49m), nn\u001b[39m.\u001b[39;49mBCELoss(),trainloader,valloader, \u001b[39m1000\u001b[39;49m,vala,\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[143], line 20\u001b[0m, in \u001b[0;36mtrain_graph_opt\u001b[1;34m(model, optimizer, loss_fn, train_loader, val_loader, epochs, dataset, number1, number2)\u001b[0m\n\u001b[0;32m     18\u001b[0m gatrix \u001b[39m=\u001b[39m [[\u001b[39mint\u001b[39m(bit) \u001b[39mfor\u001b[39;00m bit \u001b[39min\u001b[39;00m binary_string] \u001b[39mfor\u001b[39;00m binary_string \u001b[39min\u001b[39;00m gatrix]\n\u001b[0;32m     19\u001b[0m inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(torch\u001b[39m.\u001b[39mtensor(histo), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 20\u001b[0m target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msqueeze(torch\u001b[39m.\u001b[39;49mtensor(gatrix), dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m \u001b[39m#print(inputs.shape)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[39m# Training pass\u001b[39;00m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_graph_opt(net1,optim.Adam(net1.parameters(), lr=.01), nn.BCELoss(),trainloader,valloader, 1000,vala,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0 - Training loss: 0.6692572832107544\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([165, 8]) torch.Size([165, 8])\n",
      "accuracy: = 0.00, number of graphs: = 2469.00\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([256, 8]) torch.Size([256, 8])\n",
      "torch.Size([149, 8]) torch.Size([149, 8])\n",
      "accuracy: = 0.00, number of graphs: = 9877.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_graph_opt2(net3,optim\u001b[39m.\u001b[39;49mAdam(net3\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49m\u001b[39m.01\u001b[39;49m), nn\u001b[39m.\u001b[39;49mBCELoss(),trainloader,valloader, \u001b[39m1000\u001b[39;49m,vala,\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[143], line 98\u001b[0m, in \u001b[0;36mtrain_graph_opt2\u001b[1;34m(model, optimizer, loss_fn, train_loader, val_loader, epochs, dataset, number2)\u001b[0m\n\u001b[0;32m     96\u001b[0m     histo1\u001b[39m.\u001b[39mappend(traina[ticks[i]][\u001b[39m3\u001b[39m])\n\u001b[0;32m     97\u001b[0m     histo2\u001b[39m.\u001b[39mappend(traina[ticks[i]][\u001b[39m0\u001b[39m])\n\u001b[1;32m---> 98\u001b[0m     gatrix\u001b[39m.\u001b[39mappend(traina[ticks[i]][number2])\n\u001b[0;32m     99\u001b[0m gatrix \u001b[39m=\u001b[39m [[\u001b[39mint\u001b[39m(bit) \u001b[39mfor\u001b[39;00m bit \u001b[39min\u001b[39;00m binary_string] \u001b[39mfor\u001b[39;00m binary_string \u001b[39min\u001b[39;00m gatrix]\n\u001b[0;32m    100\u001b[0m inputs1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(torch\u001b[39m.\u001b[39mtensor(histo1), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_graph_opt2(net3,optim.Adam(net3.parameters(), lr=.01), nn.BCELoss(),trainloader,valloader, 1000,vala,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
